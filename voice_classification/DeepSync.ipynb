{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import tensorflow as tf\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import IPython\n",
    "# IPython.display.Audio(\"./dataset/m3/02.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_files(path):\n",
    "    return [f for f in listdir(path) if isfile(join(path, f)) and not f.endswith('.ini')]\n",
    "\n",
    "def read_audio(path ,directory, index, Tx):\n",
    "    x = np.empty((len(path),n_freq, Tx))\n",
    "    y = np.empty( ((len(path), num_classes)) )\n",
    "    for i, fl in enumerate(path):\n",
    "        try:\n",
    "            sample_rate, audio = wavfile.read(directory+fl)\n",
    "        except ValueError:\n",
    "            print(\"{} not an wav file\".format(directory+fl))\n",
    "        _, _, spectrogram = signal.spectrogram(audio, sample_rate)\n",
    "        try:\n",
    "            x[i,:,:] = spectrogram[:,:Tx]\n",
    "        except ValueError:\n",
    "            print(\"Error: Time steps too short {}\".format(directory+fl))\n",
    "        y[i,:] = to_categorical(index, num_classes)\n",
    "    return x, y\n",
    "\n",
    "def mean(X, n):\n",
    "    return X.sum()/n\n",
    "\n",
    "def variance(X, n):\n",
    "    return np.square(X).sum() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tx = 400 # The number of time steps input to the model from the spectrogram\n",
    "n_freq = 129 # Number of frequencies input to the model at each time step of the spectrogram\n",
    "mat = Tx * n_freq # Number of values in each spectrogram\n",
    "num_classes = 8 # number of output classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local_dir ='./dataset/'\n",
    "mypath = ['1/','2/','3/','4/','5/','6/','7/','8/']\n",
    "\n",
    "X_train = np.zeros((1, n_freq, Tx))\n",
    "Y_train = np.zeros((1, num_classes))\n",
    "for i, folder in enumerate(mypath):\n",
    "    files = get_files(local_dir+folder)\n",
    "    X, Y = read_audio(files, local_dir+folder, i, Tx)\n",
    "    X_train = np.append(X_train , X, axis =0)\n",
    "    Y_train = np.append(Y_train, Y, axis=0)\n",
    "\n",
    "Y_train = Y_train[1:,:].astype('int32')\n",
    "X_train = X_train[1:,:,:].astype('float32')\n",
    "\n",
    "a, b, c = X_train.shape\n",
    "X_train = np.reshape(X_train, (a, b, c, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize inputs\n",
    "# X_mean = (X_train.sum((1,2)) / mat).reshape(-1, 1, 1, 1)\n",
    "# X_variance = (np.square(X_train).sum((1,2)) / mat).reshape(-1, 1, 1, 1)\n",
    "# X_train = (X_train - X_mean) / X_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local_test_dir ='./dataset/test/'\n",
    "mypath = ['1/','2/','3/','4/','5/','6/','7/','8/']\n",
    "\n",
    "X_test = np.zeros((1, n_freq, Tx))\n",
    "Y_test = np.zeros((1, num_classes))\n",
    "for i, folder in enumerate(mypath):\n",
    "    files = get_files(local_test_dir+folder)\n",
    "    X, Y = read_audio(files, local_test_dir+folder, i, Tx)\n",
    "    X_test = np.append(X_test , X, axis =0)\n",
    "    Y_test = np.append(Y_test, Y, axis=0)\n",
    "\n",
    "Y_test = Y_test[1:,:].astype('int32')\n",
    "X_test = X_test[1:,:,:].astype('float32')\n",
    "\n",
    "d, e, f = X_test.shape\n",
    "X_test = np.reshape(X_test, (d, e, f, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize inputs\n",
    "# X_mean = (X_test.sum((1,2)) / mat).reshape(-1, 1, 1, 1)\n",
    "# X_variance = (np.square(X_test).sum((1,2)) / mat).reshape(-1, 1, 1, 1)\n",
    "# X_test = (X_test - X_mean) / X_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_examples = X_train.shape[0]\n",
    "num_steps = 250\n",
    "dropout = 0.75\n",
    "display_step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, [None, n_freq, Tx, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    print(conv1)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    print(conv1)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    print(conv2)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    print(conv2)\n",
    "    \n",
    "    # Convolution Layer\n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
    "    print(conv3)\n",
    "    conv3 = maxpool2d(conv3, k=2)\n",
    "    print(conv3)\n",
    "    \n",
    "\n",
    "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    print(out)\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 4])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 4, 8])),\n",
    "    'wc3': tf.Variable(tf.random_normal([5, 5, 8, 16])),\n",
    "    'wd1': tf.Variable(tf.random_normal([17*50*16, 256])),\n",
    "    'out': tf.Variable(tf.random_normal([256, num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([4])),\n",
    "    'bc2': tf.Variable(tf.random_normal([8])),\n",
    "    'bc3': tf.Variable(tf.random_normal([16])),\n",
    "    'bd1': tf.Variable(tf.random_normal([256])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu:0\", shape=(?, 129, 400, 4), dtype=float32)\n",
      "Tensor(\"MaxPool:0\", shape=(?, 65, 200, 4), dtype=float32)\n",
      "Tensor(\"Relu_1:0\", shape=(?, 65, 200, 8), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(?, 33, 100, 8), dtype=float32)\n",
      "Tensor(\"Relu_2:0\", shape=(?, 33, 100, 16), dtype=float32)\n",
      "Tensor(\"MaxPool_2:0\", shape=(?, 17, 50, 16), dtype=float32)\n",
      "Tensor(\"Add_1:0\", shape=(?, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "logits = conv_net(X, weights, biases, keep_prob)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train_ops = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train acc= 0.124, test acc= 0.153\n",
      "--------------------------------------------------\n",
      "epoch 10, train acc= 0.246, test acc= 0.250\n",
      "--------------------------------------------------\n",
      "epoch 20, train acc= 0.370, test acc= 0.298\n",
      "--------------------------------------------------\n",
      "epoch 30, train acc= 0.457, test acc= 0.379\n",
      "--------------------------------------------------\n",
      "epoch 40, train acc= 0.529, test acc= 0.460\n",
      "--------------------------------------------------\n",
      "epoch 50, train acc= 0.627, test acc= 0.484\n",
      "--------------------------------------------------\n",
      "epoch 60, train acc= 0.671, test acc= 0.524\n",
      "--------------------------------------------------\n",
      "epoch 70, train acc= 0.731, test acc= 0.524\n",
      "--------------------------------------------------\n",
      "epoch 80, train acc= 0.775, test acc= 0.524\n",
      "--------------------------------------------------\n",
      "epoch 90, train acc= 0.814, test acc= 0.524\n",
      "--------------------------------------------------\n",
      "epoch 100, train acc= 0.837, test acc= 0.524\n",
      "--------------------------------------------------\n",
      "epoch 110, train acc= 0.852, test acc= 0.540\n",
      "--------------------------------------------------\n",
      "epoch 120, train acc= 0.878, test acc= 0.548\n",
      "--------------------------------------------------\n",
      "epoch 130, train acc= 0.893, test acc= 0.540\n",
      "--------------------------------------------------\n",
      "epoch 140, train acc= 0.904, test acc= 0.556\n",
      "--------------------------------------------------\n",
      "epoch 150, train acc= 0.913, test acc= 0.556\n",
      "--------------------------------------------------\n",
      "epoch 160, train acc= 0.923, test acc= 0.581\n",
      "--------------------------------------------------\n",
      "epoch 170, train acc= 0.934, test acc= 0.581\n",
      "--------------------------------------------------\n",
      "epoch 180, train acc= 0.944, test acc= 0.605\n",
      "--------------------------------------------------\n",
      "epoch 190, train acc= 0.954, test acc= 0.597\n",
      "--------------------------------------------------\n",
      "epoch 200, train acc= 0.956, test acc= 0.597\n",
      "--------------------------------------------------\n",
      "epoch 210, train acc= 0.961, test acc= 0.597\n",
      "--------------------------------------------------\n",
      "epoch 220, train acc= 0.961, test acc= 0.589\n",
      "--------------------------------------------------\n",
      "epoch 230, train acc= 0.965, test acc= 0.573\n",
      "--------------------------------------------------\n",
      "epoch 240, train acc= 0.970, test acc= 0.581\n",
      "--------------------------------------------------\n",
      "epoch 250, train acc= 0.972, test acc= 0.589\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, num_steps+1):\n",
    "        \n",
    "        #training uncommnt below line if needed\n",
    "        ##sess.run(train_ops , feed_dict={X: X_train, Y: Y_train, keep_prob: dropout})\n",
    "        \n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={X: X_train, Y: Y_train, keep_prob: 1.0})\n",
    "            acct = sess.run(accuracy, feed_dict={X: X_test, Y: Y_test, keep_prob: 1.0})\n",
    "            print(\"epoch \" + str(step) + \", train acc= \" + \\\n",
    "                  \"{:.3f}\".format(acc) + \", test acc= \" + \\\n",
    "                  \"{:.3f}\".format(acct))\n",
    "            print(\"-\"*50)\n",
    "        if step % 50 == 0:\n",
    "            saver.save(sess,\"models/pre_trained_cnn.ckpt\", global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 794)\n",
      "(1, 129, 400, 1)\n"
     ]
    }
   ],
   "source": [
    "test_file = \"voicefile.wav\" # eg:-  \"voicefile.wav\" \n",
    "# test_file = \"test_music.wav\" # eg:-  \"voicefile.wav\"    \n",
    "# test_file = \"054.wav\" # eg:-  \"voicefile.wav\"  \n",
    "\n",
    "# upload 8bit, 16KHz mono audio\n",
    "try:\n",
    "    sample_rate, audio = wavfile.read(test_file)\n",
    "except ValueError:\n",
    "    print(\"{} not a wav file\".format(test_file))\n",
    "\n",
    "_, _, X_val = signal.spectrogram(audio, sample_rate)\n",
    "print(X_val.shape)\n",
    "freq, time = X_val.shape\n",
    "if time < Tx or freq < n_freq:\n",
    "    print(\"Error {}: Time steps too short  upload a longer file\\\n",
    "          or make sure that frequency is above 129 hz \".format(test_file))\n",
    "\n",
    "X_val = X_val[:n_freq,:Tx].reshape(1, n_freq, Tx, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predic = 0\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, \"models/pre_trained_cnn.ckpt-100\")\n",
    "    \n",
    "    predic = sess.run(prediction , feed_dict={X: X_val, keep_prob: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given audio file resembles class 1 from training set.\n"
     ]
    }
   ],
   "source": [
    "print(\"Given audio file resembles class {} from training set.\".format(predic.argmax()+1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
