{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dicts = pickle.load(fo, encoding='bytes')\n",
    "        \n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(Y_t, n_y):\n",
    "    Y_hot = np.zeros((n_y,Y_t.shape[1]))\n",
    "    Y_hot[Y, np.arange(Y_t.shape[1])] = 1\n",
    "    return Y_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define neural network layers and units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(layer_dims):\n",
    "    params = {}\n",
    "    for l in range(1,len(layer_dims)):\n",
    "        params[\"W\"+str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1]) * 0.01\n",
    "        params[\"b\"+str(l)] = np.zeros((layer_dims[l],1))\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    Z = np.dot(W, A) + b\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    A = np.maximum(0,Z)\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "def softmax(Z, axis=None):\n",
    "    cache = Z\n",
    "    Z = Z - Z.max(axis=axis, keepdims=True)\n",
    "    y = np.exp(Z)\n",
    "    return y / np.sum(y, axis=axis, keepdims=True), cache\n",
    "\n",
    "def sigmoid(Z):\n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    \n",
    "    return a, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    if activation == \"relu\":\n",
    "        Z, linear_cache  = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    elif activation == \"softmax\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = softmax(Z,0)\n",
    "    elif activation ==\"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "        \n",
    "    cache = (linear_cache, activation_cache)\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X, params):\n",
    "    caches = list()\n",
    "    A = X\n",
    "    L = len(params) // 2 # no of paramaters divided by 2 w1 and b1 for no of layers\n",
    "    for l in range(1, L):\n",
    "        W = params[\"W\"+str(l)]\n",
    "        b = params[\"b\"+str(l)]\n",
    "        A, cache = linear_activation_forward(A, W, b, \"relu\")\n",
    "        caches.append(cache)\n",
    "    #final layer\n",
    "    W = params[\"W\"+str(L)]\n",
    "    b = params[\"b\"+str(L)]\n",
    "    AL, cache = linear_activation_forward(A, W, b, \"softmax\")\n",
    "    caches.append(cache)\n",
    "    \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "    #logarithimic cost\n",
    "    cost = -(1/m)*np.sum((Y * np.log(AL) ) + ((1 - Y)*np.log(1-AL)))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back Propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    dW = (1/m) * np.dot(dZ, A_prev.T)\n",
    "    db = (1/m) * np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    return 1. * (dA > 0)\n",
    "\n",
    "def softmax_backward(dA, cache, y):\n",
    "    s ,_ = softmax(cache)\n",
    "    return dA*(s*(1-s))\n",
    "#     return dA * (1/dA.shape[1])\n",
    "#     return dA-y\n",
    "    \n",
    "#     J = - s[..., None] * s[:, None, :]\n",
    "#     iy, ix = np.diag_indices_from(J[0])\n",
    "#     J[:, iy, ix] = s * (1. - s) # diagonal\n",
    "#     p =  J.sum(axis=1) # sum across-rows for each sample\n",
    "#     print(p)\n",
    "#     return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, Y, activation):\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    elif activation == \"softmax\":\n",
    "        dZ = softmax_backward(dA, activation_cache, Y)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(AL, Y, caches):\n",
    "\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "    \n",
    "    # Initializing the backpropagation\n",
    "    dAL = -(1/m)*(np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    \n",
    "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"dAL, current_cache\". Outputs: \"grads[\"dAL-1\"], grads[\"dWL\"], grads[\"dbL\"]\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, Y, activation=\"softmax\")\n",
    "    \n",
    "    # Loop from l=L-2 to l=0\n",
    "    for l in reversed(range(L-1)):\n",
    "        # lth layer: (RELU -> LINEAR) gradients.\n",
    "        # Inputs: \"grads[\"dA\" + str(l + 1)], current_cache\". Outputs: \"grads[\"dA\" + str(l)] , grads[\"dW\" + str(l + 1)] , grads[\"db\" + str(l + 1)] \n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l+1)], current_cache, Y, activation=\"relu\")\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    L = len(parameters) // 2 \n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - (learning_rate * grads[\"dW\" + str(l+1)])\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - (learning_rate * grads[\"db\" + str(l+1)])\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 20, print_cost=False):#lr was 0.009\n",
    "\n",
    "#     np.random.seed(1)\n",
    "    costs = [] # keep track of cost\n",
    "    params = init_parameters(layer_dims)\n",
    "\n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        AL, caches = forward_prop(X, params)\n",
    "        \n",
    "        # Compute cost.\n",
    "        cost = compute_cost(AL, Y)\n",
    "    \n",
    "        # Backward propagation.\n",
    "        grads =  back_prop(AL, Y, caches)\n",
    " \n",
    "        # Update parameters.\n",
    "        params = update_parameters(params, grads, learning_rate)\n",
    "                \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 10 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 10 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return params, AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, Y, split=80):\n",
    "    dataset_size = X.shape[1]\n",
    "    m_train = math.floor((dataset_size * split)/100)\n",
    "    X_train = X[:,0:m_train]\n",
    "    X_test = X[:,m_train-1:-1]\n",
    "    Y_train = Y[:,0:m_train]\n",
    "    Y_test = Y[:,m_train-1:-1]\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = unpickle(\"dataset/data_batch_1\")\n",
    "labels  = unpickle(\"dataset/batches.meta\")[b'label_names']\n",
    "X = data[b'data']\n",
    "Y = np.array(data[b'labels'])\n",
    "X = data[b'data'].T\n",
    "Y = Y.reshape((1,Y.shape[0]))\n",
    "dataset_size = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_y = len(labels)\n",
    "Y = one_hot(Y,n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = train_test_split(X, Y, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train[0:6,:]\n",
    "\n",
    "m_train = X_train.shape[1]\n",
    "m_test = X_test.shape[1]\n",
    "n_x = X_train.shape[0]\n",
    "n_y = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sa[ass,np.arange(sa.shape[1])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(one_hot(np.argmax(AL, axis=0, out=sa), n_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 6.527009\n",
      "Cost after iteration 10: 3.155636\n",
      "Cost after iteration 20: 3.119325\n",
      "Cost after iteration 30: 3.083465\n",
      "Cost after iteration 40: 3.048052\n",
      "Cost after iteration 50: 3.013100\n",
      "Cost after iteration 60: 2.978641\n",
      "Cost after iteration 70: 2.944737\n",
      "Cost after iteration 80: 2.911478\n",
      "Cost after iteration 90: 2.878996\n",
      "Cost after iteration 100: 2.847463\n",
      "Cost after iteration 110: 3.243846\n",
      "Cost after iteration 120: 3.243196\n",
      "Cost after iteration 130: 3.242548\n",
      "Cost after iteration 140: 3.241899\n",
      "Cost after iteration 150: 3.241251\n",
      "Cost after iteration 160: 3.240603\n",
      "Cost after iteration 170: 3.239956\n",
      "Cost after iteration 180: 3.239309\n",
      "Cost after iteration 190: 3.238662\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ## define the network here\n",
    "layer_dims = [n_x,30,n_y]\n",
    "\n",
    "params,AL = train(X_train, Y_train, layer_dims, print_cost=True,num_iterations = 200,learning_rate=0.0075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 9, 9, 9, 9], dtype=int64)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(AL,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09993596, 0.09993596, 0.09993596, 0.09993596, 0.09993596],\n",
       "       [0.10006528, 0.10006528, 0.10006528, 0.10006528, 0.10006528],\n",
       "       [0.09993596, 0.09993596, 0.09993596, 0.09993596, 0.09993596],\n",
       "       [0.09992663, 0.09992663, 0.09992663, 0.09992663, 0.09992663],\n",
       "       [0.10006525, 0.10006525, 0.10006525, 0.10006525, 0.10006525],\n",
       "       [0.09993596, 0.09993596, 0.09993596, 0.09993596, 0.09993596],\n",
       "       [0.10006529, 0.10006529, 0.10006529, 0.10006529, 0.10006529],\n",
       "       [0.09993595, 0.09993595, 0.09993595, 0.09993595, 0.09993595],\n",
       "       [0.09993596, 0.09993596, 0.09993596, 0.09993596, 0.09993596],\n",
       "       [0.10019774, 0.10019774, 0.10019774, 0.10019774, 0.10019774]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft(dA, cache, y):\n",
    "    s ,_ = softmax(cache)\n",
    "    J = - s[..., None] * s[:, None, :]\n",
    "    iy, ix = np.diag_indices_from(J[0])\n",
    "    J[:, iy, ix] = s * (1. - s) # diagonal\n",
    "    p =  J.sum(axis=1) # sum across-rows for each sample\n",
    "    print(p)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.array([1.8658,2.2292,2.8204])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = np.array([0.26980,0.32235,0.40784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19857651 0.28559493 0.51582856]\n"
     ]
    }
   ],
   "source": [
    "AL,_ = softmax(z)\n",
    "print(AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43669145 0.12970812 0.17465947]\n"
     ]
    }
   ],
   "source": [
    "cost = ( np.multiply(Y , np.log(AL) ) + np.multiply((1-Y) , np.log(1-AL)) ) * -1/3\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.67861412  0.4665887   0.68846137]\n"
     ]
    }
   ],
   "source": [
    "dAL = -(1/m)*(np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "print(dAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.56895805, -0.        , -0.        ])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(Y , np.log10(AL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
