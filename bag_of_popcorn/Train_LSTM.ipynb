{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"dataset/labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentence(sentence):\n",
    "    reg1 = re.compile(r\"\\x3C.{1,8}\\x3E\")\n",
    "    reg2 = re.compile(\"[^a-zA-Z0-9]\")\n",
    "    a = re.sub(reg1,\"\",sentence)\n",
    "    b = re.sub(reg2,\" \",a)\n",
    "    return b.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list()\n",
    "\n",
    "for review in train[\"review\"].values:\n",
    "    sentences.append(split_sentence(review))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load the Gensim Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"imdb_word2Vec_50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.zeros((2,train['sentiment'].shape[0]), dtype=np.int16)\n",
    "Y_train[0,:] = train['sentiment'].values\n",
    "Y_train[1,:] = np.absolute(train['sentiment'].values - 1)\n",
    "Y_train = Y_train.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches(num):\n",
    "    i = batch_size\n",
    "    start  = (num*i)\n",
    "    end = (num*i) + i\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Find optimal word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = list()\n",
    "for sents in sentences:\n",
    "    num_words.append(len(sents))\n",
    "    \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(num_words, 50)\n",
    "plt.xlabel('Word Length')\n",
    "plt.ylabel('No of Words')\n",
    "plt.axis([0, 1200, 0, 8000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "num_classes = 2\n",
    "epochs = 50\n",
    "lstm_units = 64\n",
    "# learning_rate = 0.001\n",
    "num_dims = model.wv.vectors.shape[1]\n",
    "optimal_len = 250\n",
    "num_examples = len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_matrix = np.zeros((num_examples, optimal_len), dtype='int32')\n",
    "for i in range(num_examples):\n",
    "    for j in range(len(sentences[i])):\n",
    "        if j < optimal_len:\n",
    "            try:\n",
    "                id_matrix[i,j] = model.wv.vocab.get(sentences[i][j]).index\n",
    "            except AttributeError:\n",
    "                id_matrix[i,j] = 0 # for unknow words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# lookup\n",
    "idx = tf.placeholder(tf.int32, [batch_size, optimal_len], name=\"idx\")\n",
    "vectors = tf.Variable(tf.constant(model.wv.vectors))\n",
    "X_embedd = tf.nn.embedding_lookup(vectors, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [batch_size, optimal_len, num_dims],name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, [batch_size, num_classes], name=\"Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(lstm_units)\n",
    "lstm_cell = tf.nn.rnn_cell.DropoutWrapper(cell=lstm_cell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([lstm_units, num_classes]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[num_classes]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.equal(tf.argmax(prediction,1), tf.argmax(Y, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(y_pred, tf.float32))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction, labels=Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Setup Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \".\\\\tensorboard\\\\\" + datetime.datetime.now().strftime(\"%Y_%m_%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    #initializer\n",
    "    writer = tf.summary.FileWriter(logdir, sess.graph)\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(init)\n",
    "    itera = 0\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        for batch in range(Y_train.shape[0]//batch_size):\n",
    "            \n",
    "            #helper function\n",
    "            start, end = batches(batch)\n",
    "            \n",
    "            #curren batch\n",
    "            Y_batch = Y_train[start:end,:]\n",
    "            X_batch = id_matrix[start:end,:]\n",
    "\n",
    "            #find embedding for current batch\n",
    "            X_value = sess.run(X_embedd, {idx: X_batch})\n",
    "            #train the model \n",
    "            opt = sess.run(optimizer, {X: X_value, Y: Y_batch})\n",
    "            \n",
    "            # add summary every 10 iteration\n",
    "            if batch %10 == 0:\n",
    "                summary = sess.run(merged, {X: X_value, Y: Y_batch})\n",
    "                writer.add_summary(summary, itera)\n",
    "                \n",
    "            # print cost and train accuracy every 50 iteration\n",
    "            if batch % 100 == 0:\n",
    "                cost, acc = sess.run([loss, accuracy], {X: X_value, Y: Y_batch})\n",
    "                print(\"Epoch {}. Cost after {} iteration {:.3f} - acc {:.2f}\".format(e ,itera, cost, acc))\n",
    "                \n",
    "            #total loop count\n",
    "            itera+=1\n",
    "            \n",
    "        # save checkpoint every 10 epoch\n",
    "        if e % 10 == 0:\n",
    "            save_path = saver.save(sess,\"models/Word2Vec_50/pre_trained_lstm.ckpt\", global_step=e)\n",
    "            \n",
    "# close the summary writer\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
